{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6afdd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_breast_data():\n",
    "    breast = load_breast_cancer()\n",
    "    feature_names = list(breast.feature_names)\n",
    "    X, y = pd.DataFrame(breast.data, columns=feature_names), breast.target\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X,\n",
    "            'y': y,\n",
    "        },\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_adult_data():\n",
    "    df = pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        header=None)\n",
    "    df.columns = [\n",
    "        \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "        \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "        \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "    ]\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def load_heart_data():\n",
    "    # https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "    df = pd.read_csv(r'C:\\develop\\data\\heart-disease-uci\\heart.csv')\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_credit_data():\n",
    "    # https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "    df = pd.read_csv(r'C:\\develop\\data\\creditcardfraud\\creditcard.csv')\n",
    "    train_cols = df.columns[0:-1]\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label]\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_telco_churn_data():\n",
    "    # https://www.kaggle.com/blastchar/telco-customer-churn/downloads/WA_Fn-UseC_-Telco-Customer-Churn.csv/1\n",
    "    df = pd.read_csv(r'C:\\develop\\data\\telco-customer-churn\\WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "    train_cols = df.columns[1:-1] # First column is an ID\n",
    "    label = df.columns[-1]\n",
    "    X_df = df[train_cols]\n",
    "    y_df = df[label] # 'Yes, No'\n",
    "    dataset = {\n",
    "        'problem': 'classification',\n",
    "        'full': {\n",
    "            'X': X_df,\n",
    "            'y': y_df,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d8ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_validate\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier, APLRClassifier\n",
    "\n",
    "\n",
    "def format_n(x):\n",
    "    return \"{0:.3f}\".format(x)\n",
    "\n",
    "def process_model(clf, name, X, y, n_splits=3):\n",
    "    # Evaluate model\n",
    "    ss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.25, random_state=1337)\n",
    "    scores = cross_validate(\n",
    "        clf, X, y, scoring='roc_auc', cv=ss,\n",
    "        n_jobs=None, return_estimator=True\n",
    "    )\n",
    "\n",
    "    record = dict()\n",
    "    record['model_name'] = name\n",
    "    record['fit_time_mean'] = format_n(np.mean(scores['fit_time']))\n",
    "    record['fit_time_std'] = format_n(np.std(scores['fit_time']))\n",
    "    record['test_score_mean'] = format_n(np.mean(scores['test_score']))\n",
    "    record['test_score_std'] = format_n(np.std(scores['test_score']))\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_models(dataset_name, X, y, ct=None, n_splits=3, random_state=1337):\n",
    "    if ct is None:\n",
    "        is_cat = np.array([dt.kind == 'O' for dt in X.dtypes])\n",
    "        cat_cols = X.columns.values[is_cat]\n",
    "        num_cols = X.columns.values[~is_cat]\n",
    "\n",
    "        cat_ohe_step = ('ohe', OneHotEncoder(sparse_output=False,\n",
    "                                             handle_unknown='ignore'))\n",
    "\n",
    "        cat_pipe = Pipeline([cat_ohe_step])\n",
    "        num_pipe = Pipeline([('identity', FunctionTransformer())])\n",
    "        transformers = [\n",
    "            ('cat', cat_pipe, cat_cols),\n",
    "            ('num', num_pipe, num_cols)\n",
    "        ]\n",
    "        ct = ColumnTransformer(transformers=transformers)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    summary_record = {}\n",
    "    summary_record['dataset_name'] = dataset_name\n",
    "    print()\n",
    "    print('-' * 78)\n",
    "    print(dataset_name)\n",
    "    print('-' * 78)\n",
    "    print(summary_record)\n",
    "    print()\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('std', StandardScaler()),\n",
    "        ('lr', LogisticRegression(random_state=random_state)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'lr', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        # n_estimators updated from 10 to 100 due to sci-kit defaults changing in future versions\n",
    "        ('rf-100', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=random_state)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'rf-100', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('xgb', XGBClassifier(random_state=random_state, eval_metric='logloss')),\n",
    "    ])\n",
    "    record = process_model(pipe, 'xgb', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('ct', ct),\n",
    "        ('aplr', APLRClassifier(random_state=random_state, num_first_steps_with_linear_effects_only=2000)),\n",
    "    ])\n",
    "    record = process_model(pipe, 'aplr', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    # No pipeline needed due to EBM handling string datatypes\n",
    "    ebm_inter = ExplainableBoostingClassifier(n_jobs=-1, random_state=random_state)\n",
    "    record = process_model(ebm_inter, 'ebm', X, y, n_splits=n_splits)\n",
    "    print(record)\n",
    "    record.update(summary_record)\n",
    "    records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4955e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "n_splits = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f597d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------\n",
      "adult\n",
      "------------------------------------------------------------------------------\n",
      "{'dataset_name': 'adult'}\n",
      "\n",
      "{'model_name': 'lr', 'fit_time_mean': '0.532', 'fit_time_std': '0.007', 'test_score_mean': '0.907', 'test_score_std': '0.003'}\n",
      "{'model_name': 'rf-100', 'fit_time_mean': '2.646', 'fit_time_std': '0.155', 'test_score_mean': '0.903', 'test_score_std': '0.002'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1471, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [' <=50K' ' >50K']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_adult_data()\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[5], line 88\u001b[0m, in \u001b[0;36mbenchmark_models\u001b[1;34m(dataset_name, X, y, ct, n_splits, random_state)\u001b[0m\n\u001b[0;32m     82\u001b[0m records\u001b[38;5;241m.\u001b[39mappend(record)\n\u001b[0;32m     84\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     85\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m'\u001b[39m, ct),\n\u001b[0;32m     86\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier(random_state\u001b[38;5;241m=\u001b[39mrandom_state, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     87\u001b[0m ])\n\u001b[1;32m---> 88\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(record)\n\u001b[0;32m     90\u001b[0m record\u001b[38;5;241m.\u001b[39mupdate(summary_record)\n",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m, in \u001b[0;36mprocess_model\u001b[1;34m(clf, name, X, y, n_splits)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_model\u001b[39m(clf, name, X, y, n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     ss \u001b[38;5;241m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39mn_splits, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1337\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m     26\u001b[0m     record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[1;32mc:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:419\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    398\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    399\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    400\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    401\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    417\u001b[0m )\n\u001b[1;32m--> 419\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    499\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Isara Liyanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1471, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [' <=50K' ' >50K']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_adult_data()\n",
    "result = benchmark_models('adult', dataset['full']['X'], dataset['full']['y'], n_splits=n_splits)\n",
    "results.append(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
